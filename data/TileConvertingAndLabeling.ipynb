{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYl4PcS5xD8RQXiEL5485w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WikiPol/GeoAI_and_DL_Seminar_Uni_HD_4/blob/main/data/TileConvertingAndLabeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tif-Tile Preprocessing and Labeling Tools\n",
        "## This colab splits generated tif-tiles into smaller tiles, transforms them into jpgs and labels them for the intended YOLOv8 use."
      ],
      "metadata": {
        "id": "sC1HaOSD-zDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The files need to be stored in Google Drive and a connection has to be established."
      ],
      "metadata": {
        "id": "xFVKHdbQBfmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BHx8d6lKBOg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, the tiles have to be split into a size, that is better readable and has less labels per file. Adjust the input, output file and tile_size accordingly."
      ],
      "metadata": {
        "id": "0r3IsCL3Af9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5WDJ-amyDDa"
      },
      "outputs": [],
      "source": [
        "# Tif data splitting\n",
        "!pip install rasterio\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "\n",
        "# Input and output file specification\n",
        "input_folder = \"/content/drive/MyDrive/file_with_target_tifs\"\n",
        "output_folder = \"/content/drive/MyDrive/GeoAI/output_file\"\n",
        "\n",
        "# Tile size specification\n",
        "tile_size = 256\n",
        "\n",
        "# Creating output file if not available\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# checking input folder\n",
        "tif_files = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
        "if not tif_files:\n",
        "    print(\"No Tif files found\")\n",
        "else:\n",
        "    print(f\"{len(tif_files)} Tif-Files found\")\n",
        "\n",
        "# splitting process\n",
        "for tif_path in tif_files:\n",
        "    with rasterio.open(tif_path) as dataset:\n",
        "        filename = os.path.splitext(os.path.basename(tif_path))[0]\n",
        "        width, height = dataset.width, dataset.height\n",
        "\n",
        "        # computing number of files\n",
        "        num_tiles_x = (width + tile_size - 1) // tile_size\n",
        "        num_tiles_y = (height + tile_size - 1) // tile_size\n",
        "\n",
        "        print(f\"{filename}: {num_tiles_x}x{num_tiles_y} Tiles\")\n",
        "\n",
        "        # Tile extraction\n",
        "        for i in range(num_tiles_x):\n",
        "            for j in range(num_tiles_y):\n",
        "                x_off = i * tile_size\n",
        "                y_off = j * tile_size\n",
        "                window_width = min(tile_size, width - x_off)\n",
        "                window_height = min(tile_size, height - y_off)\n",
        "                window = Window(x_off, y_off, window_width, window_height)\n",
        "                tile_data = dataset.read(window=window)\n",
        "\n",
        "                # naming an save path setting\n",
        "                tile_filename = f\"{filename}_tile_{i}_{j}.tif\"\n",
        "                tile_path = os.path.join(output_folder, tile_filename)\n",
        "\n",
        "                # saving tile\n",
        "                with rasterio.open(\n",
        "                    tile_path, \"w\", driver=\"GTiff\", height=window_height, width=window_width,\n",
        "                    count=dataset.count, dtype=dataset.dtypes[0], crs=dataset.crs,\n",
        "                    transform=dataset.window_transform(window)\n",
        "                ) as tile_dst:\n",
        "                    tile_dst.write(tile_data)\n",
        "\n",
        "                print(f\"Tile saved: {tile_filename}\")\n",
        "\n",
        "print(\"End of process. Check your Google Drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data is ready to be converted into jpgs. Adjust the input and output path accordingly (temp and output will be created if no corresponding directory is found)."
      ],
      "metadata": {
        "id": "PgFEUkOWBtXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tile transformation into pngs\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "from osgeo import gdal, osr\n",
        "\n",
        "# Input, Output and a temporal storage\n",
        "input_folder = \"/content/drive/MyDrive/GeoAI/TIFF_Tiles\"\n",
        "temp_folder = \"/content/drive/MyDrive/GeoAI/temp_tiff\" # for uncompressed tifs\n",
        "output_folder = \"/content/drive/MyDrive/GeoAI/yolo_images\"\n",
        "\n",
        "os.makedirs(temp_folder, exist_ok=True)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Transforming koordinates into px considering the EPSG\n",
        "def lonlat_to_pixel_coords(lon, lat, geotransform, spatial_ref):\n",
        "    target = osr.SpatialReference()\n",
        "    target.ImportFromWkt(spatial_ref)\n",
        "\n",
        "    # Transforming the reference system\n",
        "    source = osr.SpatialReference()\n",
        "    source.ImportFromEPSG(4326)  # WGS84\n",
        "    transform = osr.CoordinateTransformation(source, target)\n",
        "    x_geo, y_geo, _ = transform.TransformPoint(lon, lat)\n",
        "\n",
        "    # Transforming into pixel coordinates\n",
        "    origin_x, pixel_width, _, origin_y, _, pixel_height = geotransform\n",
        "    pixel_x = int((x_geo - origin_x) / pixel_width)\n",
        "    pixel_y = int((y_geo - origin_y) / pixel_height)\n",
        "    return pixel_x, pixel_y\n",
        "\n",
        "#  Accesing tif files\n",
        "tif_files = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
        "total_files = len(tif_files)\n",
        "\n",
        "if total_files == 0:\n",
        "    print(\"No tif files found\")\n",
        "else:\n",
        "    print(f\" {total_files} tif files found\")\n",
        "\n",
        "for idx, filepath in enumerate(tif_files):\n",
        "    try:\n",
        "        filename = os.path.splitext(os.path.basename(filepath))[0]\n",
        "        dataset = gdal.Open(filepath, gdal.GA_ReadOnly)\n",
        "        if dataset is None:\n",
        "            print(f\"Error opening: {filepath}\")\n",
        "            continue\n",
        "\n",
        "        # Saving uncompressed tif\n",
        "        temp_tif_path = os.path.join(temp_folder, filename + \"_uncompressed.tif\")\n",
        "        driver = gdal.GetDriverByName(\"GTiff\")\n",
        "        driver.CreateCopy(temp_tif_path, dataset, 0)\n",
        "        dataset = None\n",
        "\n",
        "        dataset = gdal.Open(temp_tif_path)\n",
        "        geotransform = dataset.GetGeoTransform()\n",
        "        projection = dataset.GetProjection()\n",
        "\n",
        "        img = dataset.ReadAsArray()\n",
        "        if img is None or img.size == 0:\n",
        "            print(f\"Error loading {temp_tif_path}\")\n",
        "            continue\n",
        "\n",
        "        # RGB [B4, B3, B2]\n",
        "        if img.shape[0] >= 3:\n",
        "            red, green, blue = img[0], img[1], img[2]\n",
        "            rgb = np.stack([red, green, blue], axis=-1)\n",
        "            bgr = rgb[..., ::-1]\n",
        "\n",
        "            # Normalizing\n",
        "            bgr = bgr.astype(np.float32)\n",
        "            bgr = (bgr - bgr.min()) / (bgr.max() - bgr.min()) * 255\n",
        "            bgr = bgr.astype(np.uint8)\n",
        "\n",
        "            # Saving as jpg\n",
        "            output_path = os.path.join(output_folder, filename + \".jpg\")\n",
        "            if cv2.imwrite(output_path, bgr):\n",
        "                print(f\"‚úÖ [{idx + 1}/{total_files}] {filename}.jpg saved\")\n",
        "            else:\n",
        "                print(f\" Error saving {filename}.jpg\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Error {filename}: Not enough bands: {img.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error on {filepath}: {e}\")\n",
        "\n",
        "print(\"Conversion to jpgs finished\")"
      ],
      "metadata": {
        "id": "WmR-DOv9yGsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bevore the labeling process, adjust the paths input output and cvs path again. The cvs can be aquiered on Google Open Data and it includes the building blueprints that will be used to set the bounding boxes."
      ],
      "metadata": {
        "id": "F0E7hmncC9EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeling\n",
        "import os\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from shapely import wkt\n",
        "from shapely.geometry import box\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Input and output paths\n",
        "tile_folder = \"/content/drive/MyDrive/GeoAI/TIFF_Tiles\"\n",
        "label_folder = \"/content/drive/MyDrive/GeoAI/TIFF_Tiles_labels\"\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# CSV path needs to be specified\n",
        "csv_path = \"/content/drive/MyDrive/GeoAI/open_buildings_wkt_polygon1.csv.gz\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Cleaning the csv file\n",
        "df[\"geometry\"] = df[\"geometry\"].astype(str).str.strip('\"')\n",
        "df[\"geometry\"] = df[\"geometry\"].apply(wkt.loads)\n",
        "\n",
        "tiles = [os.path.join(tile_folder, f) for f in os.listdir(tile_folder) if f.endswith(\".tif\")]\n",
        "\n",
        "print(f\"üîç {len(tiles)} TIFF-Kacheln gefunden.\")\n",
        "\n",
        "for tif_path in tqdm(tiles):\n",
        "    try:\n",
        "        with rasterio.open(tif_path) as src:\n",
        "            bounds = box(*src.bounds)\n",
        "            transform = src.transform\n",
        "\n",
        "            # Chosing relevant geometries\n",
        "            relevant_geoms = df[df[\"geometry\"].apply(lambda g: g.intersects(bounds))]\n",
        "\n",
        "            labels = []\n",
        "            for _, row in relevant_geoms.iterrows():\n",
        "                geom = row[\"geometry\"].intersection(bounds)\n",
        "                if geom.is_empty or not geom.is_valid:\n",
        "                    continue\n",
        "\n",
        "                minx, miny, maxx, maxy = geom.bounds\n",
        "\n",
        "                x_center = ((minx + maxx) / 2 - bounds.bounds[0]) / (bounds.bounds[2] - bounds.bounds[0])\n",
        "                y_center = 1 - ((miny + maxy) / 2 - bounds.bounds[1]) / (bounds.bounds[3] - bounds.bounds[1])\n",
        "                box_width = (maxx - minx) / (bounds.bounds[2] - bounds.bounds[0])\n",
        "                box_height = (maxy - miny) / (bounds.bounds[3] - bounds.bounds[1])\n",
        "\n",
        "                class_id = 0  # relevant for label map in roboflow\n",
        "\n",
        "                labels.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\")\n",
        "\n",
        "        # Saving in compatible yolov8 format\n",
        "        label_path = os.path.join(label_folder, os.path.basename(tif_path).replace(\".tif\", \".txt\"))\n",
        "        with open(label_path, \"w\") as f:\n",
        "            f.write(\"\\n\".join(labels))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error on {tif_path}: {e}\")\n",
        "\n",
        "print(\"Label generation finished\")\n"
      ],
      "metadata": {
        "id": "D0Ezs9awyNpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the last step the data can be uploaded to Roboflow. The api key has to be generatet for the workspace specifically. Also the Ids and paths have to be adjustet."
      ],
      "metadata": {
        "id": "A301J7CmGAtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uploads labeled files to roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "import glob\n",
        "from osgeo import gdal\n",
        "\n",
        "# Roboflow initializasion\n",
        "rf = Roboflow(api_key=\"\") #<- insert generatet key from your Roboflow account into brackets\n",
        "workspaceId = 'geoai4' # workspace ID\n",
        "projectId = 'geoai4_2' # project ID\n",
        "project = rf.workspace(workspaceId).project(projectId)\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/GeoAI/yolo_images\"\n",
        "label_folder = \"/content/drive/MyDrive/GeoAI/TIFF_Tiles_labels\"\n",
        "labelmap_path = \"/content/drive/MyDrive/GeoAI/labelmap.txt\"\n",
        "\n",
        "files = glob.glob(os.path.join(input_folder, \"*.jpg\"))\n",
        "total_files = len(files)\n",
        "\n",
        "if total_files == 0:\n",
        "    print(\"No files found\")\n",
        "else:\n",
        "    print(f\" {total_files} pictures found\")\n",
        "\n",
        "# Upload process\n",
        "for idx, filepath in enumerate(files):\n",
        "    #print(idx)\n",
        "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
        "\n",
        "    try:\n",
        "        dataset = gdal.Open(filepath, gdal.GA_ReadOnly)\n",
        "        if dataset is None:\n",
        "            print(f\"Error opening: {filepath}\")\n",
        "            continue\n",
        "\n",
        "        print(project.single_upload(\n",
        "            image_path=filepath,\n",
        "            annotation_path=os.path.join(label_folder, filename + \".txt\"),\n",
        "            annotation_labelmap=labelmap_path\n",
        "        ))\n",
        "        print(f\"‚úÖ [{idx+1}/{total_files}] {filename} uploaded.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = str(e)\n",
        "        if \"already exists\" in error_message:\n",
        "            print(f\"‚è≠Ô∏è [{idx+1}/{total_files}] {filename} already exists, skip.\")\n",
        "            continue\n",
        "        else:\n",
        "            print(f\"Error on {filepath}: {e}\")"
      ],
      "metadata": {
        "id": "h35TNEFmySuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
